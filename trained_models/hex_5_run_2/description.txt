Batch size  64
RBUF        1000, start training >64 and remove first 100 when >1000
LR          Start at 0.08, patience 15, eps 5e-5 and reduce by factor of 0.5
MCTS        Search is 5 seconds per state, c_ucb = 1.4 for extra exploration
Layers:     Added two new convolution layers, increased number of filters and added dropout layers
self.conv_layers = nn.Sequential(
            nn.Conv2d(3, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Dropout(p=0.15),
            nn.Conv2d(128, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Dropout(p=0.15),
            nn.Conv2d(256, 256, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Dropout(p=0.15),
            nn.Conv2d(256, 128, 3, padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Dropout(p=0.15),
            nn.Conv2d(128, 32, 1),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.Flatten(start_dim=1)
        )
        conv_output_size = self.get_output_shape()

        self.output = nn.Sequential(
            nn.Linear(conv_output_size[1], output_size),
            nn.Softmax(dim=-1)
        )